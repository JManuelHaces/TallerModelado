{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://miro.medium.com/max/564/0*ToYXqRes95eMvIKV.png\" width=\"250px\" height=\"80px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2021\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://miro.medium.com/max/564/0*ToYXqRes95eMvIKV.png</p>\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Modelos basados en Árboles - Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un árbol de decisión es un conjunto de sentencias de la forma: si... entonces...\n",
    "\n",
    "En un árbol de decisión de clasificación, el árbol busca crear preguntas secuenciales de forma que parta los datos en grupos más pequeños. \n",
    "\n",
    "Una vez que las particiones están hechas, una decisión predictiva es hecha a través del nodo final (basado en frecuencias).\n",
    "\n",
    "**Estructura del árbol**\n",
    "\n",
    "Toma 3 cosas en cuenta:\n",
    "- Las variables predictoras (X) que se van a usar y el punto de partición del dataset.\n",
    "- La profundidad/complejidad del árbol\n",
    "- La ecuación de predicción en los últimos nodos/hojas del árbol\n",
    "\n",
    "**Hiperparámetros a ajustar**\n",
    "- Profundidad del árbol (max_depth)\n",
    "- Número mínimo de observaciones en cada split(min_samples_split)\n",
    "\n",
    "**Gini Impurity**\n",
    "Esta medida nos dice cuál es la probabilidad de clasificar erróneamente una observación. \n",
    "\n",
    "*Nota*: mientras más pequeño el valor de Gini, mejor el split. En otras palabras menor la probabilidad de clasificar erróneamente. \n",
    "\n",
    "$$Gini = p_{1}(1-p_{1})+p_{2}(1-p_{2})=2(p_{1})(p_{2})$$\n",
    "\n",
    "Donde $p_{1}$,$p_{2}$ son las probabilidades de la clase 1 y 2 respectivamente. \n",
    "\n",
    "Esto no está totalmente completo. La ecuación anterior da el gini impurity para cada sub-partición, pero el objetivo es conocer el gini impurity para toda la partición (porque los datos se dividen a la izquierda y a la derecha). Por lo tanto, necesitamos ponderarlos acordemente:\n",
    "\n",
    "$$Gini_{ponderado} = p_{I}(2(p_{I1})(p_{I2}))+p_{D}(2(p_{D1})(p_{D2}))$$\n",
    " \n",
    "Donde I=Izquierda, D=Derecha\n",
    "\n",
    "**Desventajas**\n",
    "\n",
    "- Inestabilidad del modelo: Debido a que las particiones se basan en un conjunto de datos, si se generan cambios en el conjunto de datos, esto genera cambios importantes en la estructura del árbol y especialmente en su interpretabilidad.\n",
    "\n",
    "- Rendimiento predictivo subóptimo. Nuevamente, debido a que las particiones se basan en un conjunto de datos específico, el modelo generalmente no converge con el modelo óptimo global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (accuracy_score,precision_score,recall_score)\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar los datos\n",
    "plt.title(\"Gausiana dividida en 3 clases\", fontsize='small')\n",
    "X1, Y1 = make_gaussian_quantiles(n_samples = 500,n_features=2, n_classes=3)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o', c=Y1,\n",
    "            s=25, edgecolor='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir datos en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.20,\n",
    "                                                    random_state=0,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = range(1, 20)\n",
    "\n",
    "#para el train\n",
    "training_acc = []\n",
    "for max_depth in max_depths:\n",
    "    model_1 = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    model_1.fit(X1, Y1)\n",
    "    training_acc.append(accuracy_score(Y1, model_1.predict(X1)))\n",
    "    \n",
    "#para el test    \n",
    "testing_acc = []\n",
    "for max_depth in max_depths:\n",
    "    model_2 = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    model_2.fit(X_train, y_train)\n",
    "    testing_acc.append(accuracy_score(y_test, model_2.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_depths, training_acc, color='blue', label='Training Accuracy')\n",
    "plt.plot(max_depths, testing_acc, color='green', label='Testing Accuracy')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Hyperparameter Tuning', pad=15, size=15)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando cross validation y grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "gs = GridSearchCV(model,\n",
    "                  param_grid = {'max_depth': range(1, 11),\n",
    "                                'min_samples_split': range(10, 60, 10)},\n",
    "                  cv=5,\n",
    "                  scoring='accuracy')\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear modelo usando parámetros óptimos\n",
    "new_model = DecisionTreeClassifier(max_depth=7,\n",
    "                                  min_samples_split=10)\n",
    "new_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "yhat = new_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,yhat)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(new_model, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"trees_gen/tree_multipredict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ventajas de los árboles de decisión**\n",
    "\n",
    "- No requiere escalamiento de variables\n",
    "- Puede  ser usado para datos no lineales\n",
    "- Fácil de visualizar\n",
    "- Fácil de interpretar\n",
    "\n",
    "**Desventajas de los árboles de decisión**\n",
    "\n",
    "- Es computancionalmente complejo, especialmente al usar cross-validation para ajustar los hiperparámetros\n",
    "- Un cambio pequeño en los datos puede causar grandes cambios en la estructura del árbol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
